[dataset]
dataset = cifar100
dataset_location = /data

[cnn]
architecture = resnet
depth = 20
cardinality = 8
widen_factor = 4
growth_rate = 12
compression_rate = 2

[training_hyperparameters]
print_only = False
total_epochs = 150
train_batch = 128
test_batch = 128
learning_rate = 0.1
dropout_ratio = 0.5
gamma = 0.1
momentum = 0.9
weight_decay = 5e-4
momentum_schedule = 
lr_schedule = 0 0.001 5 0.02 15 0.01 25 -1
train_val_split = 0.8

[pruning_hyperparameters]
sub_name = entire_dataset
sub_classes = 
logdir = /home/ar4414/pytorch_training/src/ar4414/pruning/logs/resnet20/cifar100/subset1/l2_prune
logfiles = pp_0/2019-10-31-10-36-12/orig pp_5/2019-10-30-20-59-24/orig pp_10/2019-10-30-21-05-23/orig pp_25/2019-10-30-21-11-26/orig pp_50/2019-10-30-21-17-53/orig pp_75/2019-10-30-21-23-25/orig pp_80/2019-10-30-21-28-43/orig
get_gops = False
prune_filters = True
finetune = True
pruning_perc = 5
finetune_budget = 35
prune_after = 5
this_layer_up = 0
prune_weights = False
metric = weights
fbs_pruning = False
fbs_finetune = False
unpruned_ratio = 1.0
unpruned_lb = 0.1
batch_lim = -1
iterative_pruning_increment = 10
iterative_pruning_epochs = 15

[entropy_hyperparameters]
entropy = False
plot_channels = False
layers = 
channels = -1
num_batches = 320
entropy_global_pruning = False

[pytorch_parameters]
manual_seed = -1
data_loading_workers = 4
gpu_id = 0
checkpoint_path = /home/ar4414/pytorch_training/src/ar4414/pruning/logs/resnet20/cifar100/entire_dataset/l1_prune
test_name = pp_5
pretrained = /home/ar4414/pytorch_training/src/ar4414/pruning/logs/resnet20/cifar100/baseline/2019-08-27-11-58-14/orig/118-model.pth.tar
resume = False
branch = False
evaluate = False
tee_printing = None

