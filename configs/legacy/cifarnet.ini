[dataset]
Dataset: cifar10
Dataset_Location: /data

[cnn]
Architecture: cifarnet
Depth: 29 
Cardinality: 8
Widen_Factor: 4 
Growth_Rate: 12 
Compression_Rate: 2

[training_hyperparameters]
Print_Only: True
Total_Epochs: 400
Train_Batch: 256
Test_Batch: 256
Learning_Rate: 0.01
Dropout_Ratio: 0.8 
Gamma: 0.1 
Momentum: 0.9 
Weight_Decay: 5e-4
Momentum_Schedule: 
LR_Schedule: 50 -1 100 -1 200 -1 300 -1
Train_Val_Split: 0.8

[pruning_hyperparameters]
Get_Gops: False
Sub_Classes:

Finetune: False
This_Layer_Up: 0
Pruning_Perc: 80
Prune_Weights: False
Prune_Filters: False 
Metric: weights

FBS_Pruning: False
FBS_Finetune: False
Unpruned_Ratio: 0.9 
Unpruned_LB: 0.1
Batch_Lim: -1

Iterative_Pruning_Increment: 10
Iterative_Pruning_Epochs: 15

[pytorch_parameters]
Manual_Seed: -1
Data_Loading_Workers: 4 
GPU_ID: 1
Checkpoint_Path: /home/ar4414/pytorch_training/src/ar4414/pruning/logs/cifarnet
Test_Name: cifar10_entire_dataset
# Pretrained: /home/ar4414/pytorch_training/src/ar4414/pruning/logs/googlenet/googlenet_cifar100_pruning_aware_baseline/orig/299-model.pth.tar
Pretrained: /home/ar4414/pytorch_training/src/ar4414/pruning/logs/fbs/googlenet/cifar100_entire_dataset/2019-08-28-17-55-39/orig/31-model.pth.tar
Resume: False
Branch: False
Evaluate: False
Tee_Printing: None
