import torch.nn as nn
import torch.nn.functional as F
import torch

from src.ar4414.pruning.pruning_layers import GatedConv2d

__all__ = ['cifarnet_gated']

class CifarNet(nn.Module):
    def __init__(self, gated=True):
        super(CifarNet, self).__init__()
        self.gconv0 = GatedConv2d(3, 64, padding=0)
        self.gconv1 = GatedConv2d(64, 64)
        self.gconv2 = GatedConv2d(64, 128, stride=2)
        self.gconv3 = GatedConv2d(128, 128)
        self.drop3 = nn.Dropout2d()
        self.gconv4 = GatedConv2d(128, 128)
        self.gconv5 = GatedConv2d(128, 192, stride=2)
        self.gconv6 = GatedConv2d(192, 192)
        self.drop6 = nn.Dropout2d()
        self.gconv7 = GatedConv2d(192, 192)
        self.pool = nn.AvgPool2d(8)
        self.fc = nn.Linear(192, 10)

    def forward(self, x):
        x = self.gconv0(x)
        x = self.gconv1(x)
        x = self.gconv2(x)
        x = self.gconv3(x)
        x = self.drop3(x)
        x = self.gconv4(x)
        x = self.gconv5(x)
        x = self.gconv6(x)
        x = self.drop6(x)
        x = self.gconv7(x)
        x = self.pool(x)
        x = x.view(-1, 192)
        x = self.fc(x)

        return  x

    def gated_forward(self, x):
        x = self.gconv0(x)
        x = self.gconv1(x)
        x = self.gconv2(x)
        x = self.gconv3(x)
        x = self.drop3(x)
        x = self.gconv4(x)
        x = self.gconv5(x)
        x = self.gconv6(x)
        x = self.drop6(x)
        x = self.gconv7(x)
        x = self.pool(x)
        x = x.view(-1, 192)
        x = self.fc(x)

        return  x

def cifarnet_gated(**kwargs):
    return CifarNet(**kwargs)
